{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5i-Yq5zDb3BP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistCustomDataset(Dataset):\n",
        "  def __init__(self, csv_file, transform=None):\n",
        "    self.transform = transform\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    self.targets = torch.tensor(self.data.loc[:, \"label\"].to_numpy())\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sample = self.data.loc[index][1:].to_numpy(dtype=np.float32).reshape(28,28)\n",
        "    target = torch.tensor(self.data.loc[index][0])\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]"
      ],
      "metadata": {
        "id": "lwQ3UX-zdaBy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the mean and standard deviation of the dataset.\n",
        "\n",
        "train_set = MnistCustomDataset(csv_file=\"/content/drive/MyDrive/Deep-Learning-Revision/mnist_dataset/fashion_mnist/fashion-mnist_train.csv\",\n",
        "                               transform = transforms.Compose([transforms.ToTensor()]))\n",
        "train_loader = DataLoader(train_set, batch_size=1024)\n",
        "\n",
        "\n",
        "total_sum = 0\n",
        "num_pixels = len(train_set) * 28 * 28\n",
        "for image, _ in train_loader: total_sum += image.sum()\n",
        "mean = total_sum/num_pixels\n",
        "\n",
        "sum_squared_error = 0\n",
        "for image, _ in train_loader: sum_squared_error += ((image-mean).pow(2)).sum()\n",
        "std = torch.sqrt(sum_squared_error/num_pixels)\n",
        "print(f\"Mean: {mean} \\t Std: {std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJJQpzb-g05e",
        "outputId": "83a2a377-40e6-417d-bfa8-6e9f330b2c55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 72.95682525634766 \t Std: 89.96687316894531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformations = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean, std)\n",
        "                                      ])"
      ],
      "metadata": {
        "id": "hr-N4iGOJ-3F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = MnistCustomDataset(csv_file=\"/content/drive/MyDrive/Deep-Learning-Revision/mnist_dataset/fashion_mnist/fashion-mnist_train.csv\",\n",
        "                               transform = transformations)"
      ],
      "metadata": {
        "id": "uIomVFWMfUFP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "PID6-sqdqja-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 128)\n",
        "    self.fc2 = nn.Linear(in_features = 128, out_features = 64)\n",
        "    self.out = nn.Linear(in_features = 64, out_features = 10)\n",
        "\n",
        "  def forward(self, t):\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    t = t.reshape(-1, 12*4*4) # flatten the tensor\n",
        "\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    t = self.fc2(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    t = self.out(t)\n",
        "\n",
        "    return t"
      ],
      "metadata": {
        "id": "_6GcR09VumAi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network()\n",
        "network.to(device)"
      ],
      "metadata": {
        "id": "hnQvQtDJCih5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a14526-612d-4086-983d-0ddf202cb22d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=192, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1_pgi-bDAmP",
        "outputId": "eb4ecab5-af7c-47da-cfce-d715efaaf8c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=192, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6tdDttc0pFQL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(params):\n",
        "    Run = namedtuple('Run', params.keys())\n",
        "    runs = []\n",
        "    for v in product(*params.values()):\n",
        "      runs.append(Run(*v))\n",
        "    return runs"
      ],
      "metadata": {
        "id": "lHqRzsyypFcE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunManager():\n",
        "  def __init__(self):\n",
        "    self.epoch_count = 0\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "    self.epoch_start_time = None\n",
        "\n",
        "    self.run_params = None\n",
        "    self.run_count = 0\n",
        "    self.run_data = []\n",
        "    self.run_start_time = None\n",
        "\n",
        "    self.network = None\n",
        "    self.loader = None\n",
        "  \n",
        "  def begin_run(self, run, network, loader):\n",
        "    self.run_start_time = time.time()\n",
        "    self.run_params = run\n",
        "    self.run_count += 1\n",
        "    self.network = network\n",
        "    self.loader = loader\n",
        "  \n",
        "  def end_run(self):\n",
        "    self.epoch_count = 0\n",
        "\n",
        "  def begin_epoch (self):\n",
        "    self.epoch_start_time = time.time()\n",
        "    self.epoch_count += 1\n",
        "    self.epoch_loss = 0\n",
        "    self.epoch_num_correct = 0\n",
        "  \n",
        "  def end_epoch(self):\n",
        "    epoch_duration = time.time() - self.epoch_start_time\n",
        "    run_duration = time.time() - self.run_start_time\n",
        "\n",
        "    loss = self.epoch_loss / len(self.loader.dataset)\n",
        "    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
        "\n",
        "\n",
        "    results = OrderedDict()\n",
        "    results[\"run\"] = self.run_count\n",
        "    results[\"epoch\"] = self.epoch_count\n",
        "    results[\"loss\"] = loss\n",
        "    results[\"accuracy\"] = accuracy\n",
        "    results[\"epoch_duration\"] = epoch_duration\n",
        "    results[\"run_duration\"] = run_duration\n",
        "\n",
        "    for k, v in self.run_params._asdict().items():\n",
        "      results[k] = v\n",
        "\n",
        "    self.run_data.append(results)\n",
        "\n",
        "    df = pd.DataFrame.from_dict(self.run_data, orient=\"columns\")\n",
        "    clear_output(wait=True)\n",
        "    display(df)\n",
        "  \n",
        "  def track_loss(self, loss):\n",
        "    self.epoch_loss += loss.item() * self.loader.batch_size\n",
        "\n",
        "  def track_num_correct(self, preds, labels):\n",
        "    self.epoch_num_correct += self.get_num_correct(preds, labels)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def get_num_correct(self, preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "  def save(self, fileName):\n",
        "    pd.DataFrame.from_dict(self.run_data, orient=\"columns\").to_csv(f\"{fileName}.csv\")\n",
        "\n",
        "    with open(f\"{fileName}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "RTJR3wjnssXM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = OrderedDict(\n",
        "    lr = [0.001, 0.003],\n",
        "    batch_size = [1024]\n",
        ")\n",
        "\n",
        "run_manager = RunManager()\n",
        "\n",
        "for run in RunBuilder.get_runs(params):\n",
        "  network = Network()\n",
        "  loader = DataLoader(train_set, batch_size=run.batch_size, shuffle=True)\n",
        "  optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
        "\n",
        "  run_manager.begin_run(run, network, loader)\n",
        "  for epoch in range(20):\n",
        "    run_manager.begin_epoch()\n",
        "    for batch in loader:\n",
        "      images, labels = batch\n",
        "\n",
        "      preds = network(images)\n",
        "      loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      run_manager.track_loss(loss)\n",
        "      run_manager.track_num_correct(preds, labels)\n",
        "    run_manager.end_epoch()\n",
        "  run_manager.end_run()\n",
        "run_manager.save(\"results\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XEiCrAnNp-zv",
        "outputId": "fb5c10a9-f9e7-4d16-c50c-f412eef47de4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    run  epoch      loss  accuracy  epoch_duration  run_duration     lr  \\\n",
              "0     1      1  1.369948  0.542933       34.291605     34.291611  0.001   \n",
              "1     1      2  0.739713  0.724733       34.012076     68.318216  0.001   \n",
              "2     1      3  0.611465  0.770567       35.195183    103.527538  0.001   \n",
              "3     1      4  0.541582  0.797850       34.013212    137.552859  0.001   \n",
              "4     1      5  0.491806  0.820417       32.810585    170.382180  0.001   \n",
              "5     1      6  0.460201  0.834417       33.288192    203.683328  0.001   \n",
              "6     1      7  0.432333  0.844500       33.273493    236.971959  0.001   \n",
              "7     1      8  0.418974  0.849617       32.780437    269.763561  0.001   \n",
              "8     1      9  0.401485  0.855150       33.876072    303.651075  0.001   \n",
              "9     1     10  0.384300  0.863000       32.409887    336.073388  0.001   \n",
              "10    1     11  0.367852  0.868150       33.390555    369.474794  0.001   \n",
              "11    1     12  0.360097  0.871050       32.388600    401.876522  0.001   \n",
              "12    1     13  0.350402  0.874800       32.645258    434.532999  0.001   \n",
              "13    1     14  0.342371  0.878583       33.051610    467.605302  0.001   \n",
              "14    1     15  0.336950  0.879483       32.412580    500.029845  0.001   \n",
              "15    1     16  0.332899  0.879983       33.087974    533.130265  0.001   \n",
              "16    1     17  0.323349  0.884083       32.650830    565.793137  0.001   \n",
              "17    1     18  0.320340  0.884700       32.900759    598.707051  0.001   \n",
              "18    1     19  0.313579  0.888467       32.288111    631.013715  0.001   \n",
              "19    1     20  0.309809  0.889667       32.273233    663.299233  0.001   \n",
              "20    2      1  0.975447  0.652133       33.628900     33.628906  0.003   \n",
              "21    2      2  0.544008  0.793017       31.984681     65.632179  0.003   \n",
              "22    2      3  0.460506  0.832833       33.619837     99.267247  0.003   \n",
              "23    2      4  0.404931  0.855033       32.161146    131.450658  0.003   \n",
              "24    2      5  0.373755  0.865117       33.001307    164.465410  0.003   \n",
              "25    2      6  0.355864  0.872517       32.912764    197.402647  0.003   \n",
              "26    2      7  0.338666  0.877683       32.370619    229.786673  0.003   \n",
              "27    2      8  0.317115  0.885817       32.944806    262.749766  0.003   \n",
              "28    2      9  0.310580  0.888883       32.091661    294.860076  0.003   \n",
              "29    2     10  0.297569  0.893150       31.958532    326.833772  0.003   \n",
              "30    2     11  0.290856  0.894883       33.059500    359.909794  0.003   \n",
              "31    2     12  0.289128  0.895467       31.955161    391.882591  0.003   \n",
              "32    2     13  0.280583  0.897617       32.691809    424.589550  0.003   \n",
              "33    2     14  0.266008  0.903017       32.198498    456.815368  0.003   \n",
              "34    2     15  0.263283  0.905150       32.172073    489.004239  0.003   \n",
              "35    2     16  0.257484  0.906417       33.010525    522.030058  0.003   \n",
              "36    2     17  0.253550  0.907667       32.097666    554.146686  0.003   \n",
              "37    2     18  0.245148  0.910400       32.389445    586.556109  0.003   \n",
              "38    2     19  0.244635  0.910083       32.477418    619.062519  0.003   \n",
              "39    2     20  0.235583  0.914383       32.181425    651.261436  0.003   \n",
              "\n",
              "    batch_size  \n",
              "0         1024  \n",
              "1         1024  \n",
              "2         1024  \n",
              "3         1024  \n",
              "4         1024  \n",
              "5         1024  \n",
              "6         1024  \n",
              "7         1024  \n",
              "8         1024  \n",
              "9         1024  \n",
              "10        1024  \n",
              "11        1024  \n",
              "12        1024  \n",
              "13        1024  \n",
              "14        1024  \n",
              "15        1024  \n",
              "16        1024  \n",
              "17        1024  \n",
              "18        1024  \n",
              "19        1024  \n",
              "20        1024  \n",
              "21        1024  \n",
              "22        1024  \n",
              "23        1024  \n",
              "24        1024  \n",
              "25        1024  \n",
              "26        1024  \n",
              "27        1024  \n",
              "28        1024  \n",
              "29        1024  \n",
              "30        1024  \n",
              "31        1024  \n",
              "32        1024  \n",
              "33        1024  \n",
              "34        1024  \n",
              "35        1024  \n",
              "36        1024  \n",
              "37        1024  \n",
              "38        1024  \n",
              "39        1024  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc61943c-8714-426a-81b7-8e3b88e8b3a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>epoch_duration</th>\n",
              "      <th>run_duration</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.369948</td>\n",
              "      <td>0.542933</td>\n",
              "      <td>34.291605</td>\n",
              "      <td>34.291611</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.739713</td>\n",
              "      <td>0.724733</td>\n",
              "      <td>34.012076</td>\n",
              "      <td>68.318216</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.611465</td>\n",
              "      <td>0.770567</td>\n",
              "      <td>35.195183</td>\n",
              "      <td>103.527538</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.541582</td>\n",
              "      <td>0.797850</td>\n",
              "      <td>34.013212</td>\n",
              "      <td>137.552859</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.491806</td>\n",
              "      <td>0.820417</td>\n",
              "      <td>32.810585</td>\n",
              "      <td>170.382180</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.460201</td>\n",
              "      <td>0.834417</td>\n",
              "      <td>33.288192</td>\n",
              "      <td>203.683328</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0.432333</td>\n",
              "      <td>0.844500</td>\n",
              "      <td>33.273493</td>\n",
              "      <td>236.971959</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.418974</td>\n",
              "      <td>0.849617</td>\n",
              "      <td>32.780437</td>\n",
              "      <td>269.763561</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0.401485</td>\n",
              "      <td>0.855150</td>\n",
              "      <td>33.876072</td>\n",
              "      <td>303.651075</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0.384300</td>\n",
              "      <td>0.863000</td>\n",
              "      <td>32.409887</td>\n",
              "      <td>336.073388</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0.367852</td>\n",
              "      <td>0.868150</td>\n",
              "      <td>33.390555</td>\n",
              "      <td>369.474794</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0.360097</td>\n",
              "      <td>0.871050</td>\n",
              "      <td>32.388600</td>\n",
              "      <td>401.876522</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0.350402</td>\n",
              "      <td>0.874800</td>\n",
              "      <td>32.645258</td>\n",
              "      <td>434.532999</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0.342371</td>\n",
              "      <td>0.878583</td>\n",
              "      <td>33.051610</td>\n",
              "      <td>467.605302</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0.336950</td>\n",
              "      <td>0.879483</td>\n",
              "      <td>32.412580</td>\n",
              "      <td>500.029845</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0.332899</td>\n",
              "      <td>0.879983</td>\n",
              "      <td>33.087974</td>\n",
              "      <td>533.130265</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>0.323349</td>\n",
              "      <td>0.884083</td>\n",
              "      <td>32.650830</td>\n",
              "      <td>565.793137</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0.320340</td>\n",
              "      <td>0.884700</td>\n",
              "      <td>32.900759</td>\n",
              "      <td>598.707051</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0.313579</td>\n",
              "      <td>0.888467</td>\n",
              "      <td>32.288111</td>\n",
              "      <td>631.013715</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.309809</td>\n",
              "      <td>0.889667</td>\n",
              "      <td>32.273233</td>\n",
              "      <td>663.299233</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975447</td>\n",
              "      <td>0.652133</td>\n",
              "      <td>33.628900</td>\n",
              "      <td>33.628906</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.544008</td>\n",
              "      <td>0.793017</td>\n",
              "      <td>31.984681</td>\n",
              "      <td>65.632179</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.460506</td>\n",
              "      <td>0.832833</td>\n",
              "      <td>33.619837</td>\n",
              "      <td>99.267247</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.404931</td>\n",
              "      <td>0.855033</td>\n",
              "      <td>32.161146</td>\n",
              "      <td>131.450658</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.373755</td>\n",
              "      <td>0.865117</td>\n",
              "      <td>33.001307</td>\n",
              "      <td>164.465410</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0.355864</td>\n",
              "      <td>0.872517</td>\n",
              "      <td>32.912764</td>\n",
              "      <td>197.402647</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.338666</td>\n",
              "      <td>0.877683</td>\n",
              "      <td>32.370619</td>\n",
              "      <td>229.786673</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0.317115</td>\n",
              "      <td>0.885817</td>\n",
              "      <td>32.944806</td>\n",
              "      <td>262.749766</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0.310580</td>\n",
              "      <td>0.888883</td>\n",
              "      <td>32.091661</td>\n",
              "      <td>294.860076</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0.297569</td>\n",
              "      <td>0.893150</td>\n",
              "      <td>31.958532</td>\n",
              "      <td>326.833772</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0.290856</td>\n",
              "      <td>0.894883</td>\n",
              "      <td>33.059500</td>\n",
              "      <td>359.909794</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.289128</td>\n",
              "      <td>0.895467</td>\n",
              "      <td>31.955161</td>\n",
              "      <td>391.882591</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>0.280583</td>\n",
              "      <td>0.897617</td>\n",
              "      <td>32.691809</td>\n",
              "      <td>424.589550</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>0.266008</td>\n",
              "      <td>0.903017</td>\n",
              "      <td>32.198498</td>\n",
              "      <td>456.815368</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>0.263283</td>\n",
              "      <td>0.905150</td>\n",
              "      <td>32.172073</td>\n",
              "      <td>489.004239</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>0.257484</td>\n",
              "      <td>0.906417</td>\n",
              "      <td>33.010525</td>\n",
              "      <td>522.030058</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>0.253550</td>\n",
              "      <td>0.907667</td>\n",
              "      <td>32.097666</td>\n",
              "      <td>554.146686</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>0.245148</td>\n",
              "      <td>0.910400</td>\n",
              "      <td>32.389445</td>\n",
              "      <td>586.556109</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>0.244635</td>\n",
              "      <td>0.910083</td>\n",
              "      <td>32.477418</td>\n",
              "      <td>619.062519</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>0.235583</td>\n",
              "      <td>0.914383</td>\n",
              "      <td>32.181425</td>\n",
              "      <td>651.261436</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc61943c-8714-426a-81b7-8e3b88e8b3a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc61943c-8714-426a-81b7-8e3b88e8b3a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc61943c-8714-426a-81b7-8e3b88e8b3a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}